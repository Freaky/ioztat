#!/usr/bin/env python3
# Based on https://www.reddit.com/r/zfs/comments/s0gxp0/ok_i_made_it_tool_to_show_io_for_individual/

# BSD 2-Clause License
#
# Copyright (c) 2022, Openoid LLC, on behalf of the r/zfs community
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# 1. Redistributions of source code must retain the above copyright notice, this
#    list of conditions and the following disclaimer.
#
# 2. Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

PROGRAM_VERSION = '2.0.0-dev'

import argparse
import math
import os
import re
import shutil
import sys
import time

class Dataset:
    timestamp = 0
    name = ''
    writes = 0
    nwritten = 0
    reads = 0
    nread = 0

    def __init__(self, data = None):
        if data:
            self.timestamp = int(data['timestamp'])
            self.name = data['dataset_name']
            self.reads = int(data['reads'])
            self.nread = int(data['nread'])
            self.writes = int(data['writes'])
            self.nwritten = int(data['nwritten'])

################################################################################
# Platform specific section
#
# Must implement parseDatasets(pool?): dict(name: Dataset)
################################################################################
if sys.platform.startswith("linux"):
    import glob

    def parseDatasets(pool = None):
        datasets = {}
        search = glob.escape(pool) if pool else '*'
        for file in glob.glob(os.path.join('/proc/spl/kstat/zfs', search, 'objset-*')):
            # Shortened example of these files:
            #############################################
            # 31 1 0x01 7 2160 6165792836 1634992995579
            # name             type data
            # dataset_name     7    rpool/ROOT/default
            #############################################
            # Field 7 of the header is a nanosecond data snapshot timestamp.
            # Conveniently, dataset names may not contain spaces.
            with open(file, 'r') as f:
                header, _fieldnames, *fields = [line.split() for line in f]
                fields.append(("timestamp", None, header[6]))
                ds = Dataset({field[0]: field[2] for field in fields if len(field) > 2})
                datasets[ds.name] = ds
        return datasets

elif sys.platform.startswith("freebsd"):
    try:
        # Attempt to use py-sysctl if available for best performance
        import sysctl
    except ImportError:
        # Otherwise make a simple sysctl(8) polyfill hopefully sufficient for our needs
        import subprocess

        class SysctlOid:
            def __init__(self, name = '', value = None):
                self.name = name
                self.value = value

        class sysctl:
            def filter(oid):
                r = subprocess.run(["sysctl", "-e", oid], capture_output=True, check=True, text=True)
                stats = [line.split("=", 2) for line in r.stdout.split("\n")]
                return [SysctlOid(*nv) for nv in stats if len(nv) == 2]

    from collections import defaultdict

    def parseDatasets(pool = None):
        # We're interested in kstat.zfs.*.dataset.objset-*.*
        # Note objset ID's are only unique to individual pools
        oid = "kstat.zfs."
        if pool:
            oid += pool + ".dataset."

        timestamp = time.monotonic_ns()
        ds = defaultdict(lambda: { 'timestamp': timestamp })
        for ctl in sysctl.filter(oid):
            name = ctl.name.rsplit(".", 4)
            if len(name) == 5 and name[2] == 'dataset':
                _, pool, _, objset, oid = name
                ds[(pool, objset)][oid] = ctl.value

        return {dataset.name: dataset for dataset in map(Dataset, ds.values())}

else:
    print("Unsupported platform: " + sys.platform)
    exit(1)

################################################################################

class DatasetDiff:
    def __init__(self, old, new):
        self.name = new.name
        self.timediff = (new.timestamp - old.timestamp) / 1e9
        self.reads = new.reads - old.reads
        self.nread = new.nread - old.nread
        self.writes = new.writes - old.writes
        self.nwritten = new.nwritten - old.nwritten
        self.rareq_sz = self.nread / self.reads if self.reads else 0
        self.wareq_sz = self.nwritten / self.writes if self.writes else 0

        if self.timediff:
            self.reads /= self.timediff
            self.nread /= self.timediff
            self.writes /= self.timediff
            self.nwritten /= self.timediff

    def nonzero(self):
        """True if this DatasetDiff has any non-zero deltas"""
        return self.reads or self.writes or self.nread or self.nwritten

def calcDiff(prevdatasets, datasets):
    return [DatasetDiff(prevdatasets[key], datasets[key]) for key in datasets.keys() & prevdatasets.keys()]

def calcDiffFromStart(datasets):
    zero = Dataset()
    return [DatasetDiff(zero, dataset) for dataset in datasets.values()]

def dataset_iter(pools):
    """Iterate over name: Dataset for pools"""
    if pools:
        while True:
            yield {name: dataset for pool in pools for name, dataset in parseDatasets(pool).items()}
    else:
        while True:
            yield parseDatasets()

def diff_iter(pools):
    """Iterate over [DatasetDiff] for pools"""
    it = dataset_iter(pools)
    prevdatasets = next(it)
    # yield the initial summary
    yield calcDiffFromStart(prevdatasets)

    for datasets in it:
        yield calcDiff(prevdatasets, datasets)
        prevdatasets = datasets

def filter_diff_iter(pools, pattern, nonzero):
    """Iterate over [DatasetDiff] for pools filtered by a name pattern and their d.nonzero() state"""
    for diff in diff_iter(pools):
        yield list(filter(lambda d: pattern.match(d.name) and (not nonzero or d.nonzero()), diff))

def delay_iter(it, interval):
    """Add a delay after each iteration of a provided iterator"""
    for item in it:
        yield item
        time.sleep(interval)

def skip_iter(it, count):
    """Skip count iterations of the iterator"""
    for _ in range(count):
        next(it)
    return it

def take_iter(it, count):
    """Yield at most count items from iterator"""
    while count > 0:
        yield next(it)
        count -= 1

################################################################################
# Column formatting

class Column:
    def __init__(self, name, width=0, format=str, just=None):
        self.name = name
        self.width = width
        self.format = format
        self.just = just

    def stringify(self, value):
        return self.justify(str(self.format(value)))

    def justify(self, string):
        if self.just:
            return self.just(string, self.width)
        else:
            return string

class ColumnGroup:
    def __init__(self, name, columns, width=0, just=str.center):
        self.name = name
        self.columns = columns
        self.width = width
        self.just = just

    def justify(self, string):
        if self.just:
            return self.just(string, self.width + sum([c.width for c in self.columns]))
        else:
            return string

class ColumnFormatter:
    def __init__(self, column_separator = '  ', row_separator = '-', buffer = []):
        self.columns = []
        self.groups = None
        self.column_separator = column_separator
        self.row_separator = row_separator
        self.buffer = buffer

    def add_column(self, name, **args):
        self.columns.append(Column(name, **args))

    def add_group(self, name='', colspan=1, just=str.center):
        if self.groups is None:
            self.groups = ColumnGroupFormatter(column_separator=column_separator, buffer=self.buffer)

        self.groups.add_column(name, columns=self.columns[-colspan:], width=len(self.column_separator) * (colspan - 1), just=just)

    def set_column_width(self, column, width):
        self.columns[column].width = width

    def get_printed_width(self, start, stop=None):
        return sum((c.width + len(self.column_separator) for c in self.columns[start:stop]))

    def print_columns(self, *columns):
        formatted = (c.stringify(column) for (c, column) in zip(self.columns, columns))
        self.print(self.column_separator.join(formatted))

    def print_header(self):
        if self.groups:
            self.groups.print_header()

        formatted = (c.justify(c.name) for c in self.columns)
        self.print(self.column_separator.join(formatted))

    def print_divider(self):
        self.print(self.column_separator.join([''.ljust(c.width, self.row_separator) for c in self.columns]))

    def print(self, string, end="\n"):
        self.buffer.append(string + end)

    def flush(self, lines=None):
        buffer = ''.join(self.buffer)
        if lines:
            buffer = "\n".join(buffer.split("\n", lines)[:lines])
        print(buffer, end='')
        self.buffer.clear()

class ColumnGroupFormatter(ColumnFormatter):
    def add_column(self, name, **args):
        self.columns.append(ColumnGroup(name, **args))

################################################################################
# General formatting

SIZE_PREFIX = ('', 'K', 'M', 'G', 'T', 'P', 'E')
SIZE_PREFIX_MAX = len(SIZE_PREFIX) - 1
POWERS_1000 = [pow(1000, i) for i in range(len(SIZE_PREFIX))]
POWERS_1024 = [pow(1024, i) for i in range(len(SIZE_PREFIX))]
FORMATS_BY_PRECISION = ['{:.2f}{}', '{:.1f}{}', '{:.0f}{}']

def number_to_human(num, length, decimal = False):
    """Format a number to a SI decimal or binary string representation that
    should fit within length bytes"""
    if decimal:
        divisor = 1000
        powers = POWERS_1000
    else:
        divisor = 1024
        powers = POWERS_1024

    n = num
    index = 0
    while n >= divisor and index <= SIZE_PREFIX_MAX:
        n /= divisor
        index += 1

    u = SIZE_PREFIX[index]

    if index == 0 or num % powers[index] == 0:
        return str(int(n)) + u

    for fmt in FORMATS_BY_PRECISION:
        ret = fmt.format(n, u)
        if len(ret) <= length:
            return ret
    return ret

def format_dataset(path, limit, ellipsis = '+'):
    """Truncate a dataset name to a limit"""
    if len(path) <= limit:
        return path

    # Always display the pool name
    components = path.split('/', 1)
    ret = components[0]
    if len(components) > 1:
        ret += '/' + ellipsis + components[1][-(limit - (len(ret) + len(ellipsis) + 1)):]
    return ret

PATH_INDENT = '  '
def indent_dataset_path(name, depth, limit):
    """Indent name by depth PATH_INDENTS constrained by limit"""
    if (len(PATH_INDENT) * depth) + len(name) > limit:
        return ('+' + name).rjust(limit - 1)[:limit]
    return (PATH_INDENT * depth) + name

def print_format_dataset(name, last_path, limit, print=print):
    """Take a path, print any elements not in last_path, and return a formatted name"""
    cur_path = name.split('/')
    common = os.path.commonprefix([last_path, cur_path])
    for i, segment in enumerate(cur_path[len(common):-1]):
        print(indent_dataset_path(segment, len(common) + i, limit))

    return (indent_dataset_path(cur_path[-1], len(cur_path) - 1, limit), cur_path)

################################################################################

SORTS = {
    'name':       {'key': lambda x: x.name},
    'operations': {'key': lambda x: x.reads + x.writes,   'reverse': True},
    'reads':      {'key': lambda x: x.reads,              'reverse': True},
    'writes':     {'key': lambda x: x.writes,             'reverse': True},
    'throughput': {'key': lambda x: x.nread + x.nwritten, 'reverse': True},
    'nread':      {'key': lambda x: x.nread,              'reverse': True},
    'nwritten':   {'key': lambda x: x.nwritten,           'reverse': True},
}
SORT_DISPLAY = list(SORTS.keys())
SORT_ALIAS = {
    'operations': ['io', 'ops', 'iops'],
    'reads': ['read', 'rps'],
    'writes': ['write', 'wps'],
    'throughput': ['bandwidth'],
    'nread': ['nreads', 'rmbps'],
    'nwritten': ['nwrite', 'nwrites', 'wmbps'],
}
for name, aliases in SORT_ALIAS.items():
    for alias in aliases:
        SORTS[alias] = SORTS[name]

# Keep this ordered alphabetically
parser = argparse.ArgumentParser(description='iostat for ZFS datasets', add_help=False)
parser.add_argument('dataset', type=str, nargs='*', help='ZFS dataset')
parser.add_argument('interval [count]', nargs='?',
                          help='seconds between reports and number of reports')
parser.add_argument('-c', dest='count', type=int,
                          help='number of reports generated')
parser.add_argument('-D', dest='decimal', action='store_true',
                          help='display bytes in decimal powers of 1000 instead of 1024')
parser.add_argument('-e', dest='exact', action='store_true',
                          help='show exact values without truncation or scaling')
parser.add_argument('-H', dest='scripted', action='store_true',
                          help='scripted mode, skip headers and tab-separate')
parser.add_argument('-h', '--help', action='help',
                          help='show this help message and exit')
parser.add_argument('-i', dest='interval', type=float,
                          help='interval between reports (in seconds)')
parser.add_argument('-N', dest='headeronce', action='store_true',
                          help='display headers at most once')
parser.add_argument('-n', dest='nonrecursive', action='store_true',
                          help='do not recurse into child datasets')
parser.add_argument('-o', dest='overwrite', action='store_true',
                          help='overwrite old reports in terminal')
group = parser.add_mutually_exclusive_group()
group.add_argument('-P', dest='fullname', action='store_true', default=None,
                         help='display dataset names on a single line')
group.add_argument('-p', dest='fullname', action='store_false', default=None,
                         help='display dataset names as an abbreviated tree')
parser.add_argument('-s', dest='sort', type=str.lower, default='name',
                          choices=SORTS.keys(), metavar='{%s}' % ','.join(SORT_DISPLAY),
                          help='sort by the specified field')
parser.add_argument('-T', dest='timestamp', choices=['u', 'd'],
                          help='prefix each report with a Unix timestamp or formatted date')
parser.add_argument('-V', '--version', action='version', version='%(prog)s ' + PROGRAM_VERSION)
parser.add_argument('-y', dest='skip', action='store_const', default=0, const=1,
                          help='skip the initial "summary" report')
parser.add_argument('-z', dest='nonzero', action='store_true',
                          help='suppress datasets with zero activity')

args = parser.parse_args()

def is_positive_float(value):
    try:
        value = float(value)
        # We want to avoid parsing 'inf' and 'nan', as these are valid pool names
        # NaN always compares False with another float, so just guard against inf
        return value > 0.0 and not math.isinf(value)
    except ValueError:
        return False

if len(args.dataset) > 0 and is_positive_float(args.dataset[-1]):
    args.interval = float(args.dataset.pop())
    if len(args.dataset) > 0 and is_positive_float(args.dataset[-1]):
        args.count = int(round(args.interval))
        args.interval = float(args.dataset.pop())

if args.count is not None and not args.count > 0:
    parser.error('count must be positive')
if args.interval is not None and not is_positive_float(args.interval):
    parser.error('interval must be positive')

# If there's no interval but a count, default to one second
if args.interval is None and args.count:
    args.interval = 1.0

if args.count is None and args.interval is None:
    args.count = 1
    args.interval = 1.0

# Enable full paths if we're not sorting by name or in nonzero mode, unless otherwise specified
if args.fullname is None:
    args.fullname = args.sort != 'name' or args.scripted or args.exact or args.nonzero

pools = {dataset.split('/')[0] for dataset in args.dataset}
if args.nonrecursive:
    # Make each match exact.
    dataset_pattern = re.compile("|".join(("\A" + re.escape(ds) + "\Z" for ds in sorted(args.dataset))))
else:
    # Accept either an exact match or one with an additional component
    dataset_pattern = re.compile("|".join(("\A" + re.escape(ds) + "(?:\Z|/[^/]+)" for ds in sorted(args.dataset))))

if args.fullname:
    calc_name_width = len
else:
    def calc_name_width(path):
        segments = path.split('/')
        return (len(segments[0:-1]) * len(PATH_INDENT)) + len(segments[-1])

if args.scripted:
    column_separator = "\t"
    name_just = None
    num_just = None
    field_width = 0
else:
    column_separator = '  '
    name_just = str.ljust
    num_just = str.rjust
    field_width = 11 if args.exact else 5

format_iops = round if args.exact else lambda num: number_to_human(num, field_width, True)
format_bytes = round if args.exact else lambda num: number_to_human(num, field_width, args.decimal)

formatter = ColumnFormatter(column_separator = column_separator, row_separator = '-')
formatter.add_column('dataset', just=name_just)
formatter.add_group()
formatter.add_column('read',  width=field_width, format=format_iops, just=num_just)
formatter.add_column('write', width=field_width, format=format_iops, just=num_just)
formatter.add_group('operations', 2)
formatter.add_column('read',  width=field_width, format=format_bytes, just=num_just)
formatter.add_column('write', width=field_width, format=format_bytes, just=num_just)
formatter.add_group('throughput', 2)
formatter.add_column('read',  width=field_width, format=format_bytes, just=num_just)
formatter.add_column('write', width=field_width, format=format_bytes, just=num_just)
formatter.add_group('opsize', 2)

diff_loop = filter_diff_iter(pools, dataset_pattern, args.nonzero)

if args.interval:
    diff_loop = delay_iter(diff_loop, args.interval)

if args.skip:
    diff_loop = skip_iter(diff_loop, args.skip)

if args.count:
    diff_loop = take_iter(diff_loop, args.count)

if not args.overwrite:
    diff_loop = filter(None, diff_loop)

try:
    max_name_width = 0

    for iteration, diff in enumerate(diff_loop):
        # Always sort by name first, so the main sort has it as a secondary
        diff.sort(**SORTS['name'])
        if args.sort != 'name':
            diff.sort(**SORTS[args.sort])

        width, height = shutil.get_terminal_size()
        avail_width = width - formatter.get_printed_width(1, 7)
        max_name_width = max(max_name_width, max((calc_name_width(d.name) for d in diff), default=10))
        name_width = max(10, min([avail_width, max_name_width]))
        formatter.set_column_width(0, name_width)

        if args.overwrite:
            # Clear the screen and move the cursor to the upper-left
            formatter.print("\033[2J\033[1;1H", end = '')

        if args.timestamp == 'u':
            formatter.print(int(time.time()))
        elif args.timestamp == 'd':
            formatter.print(time.strftime('%c'))

        if (not args.scripted) and (args.overwrite or iteration == 0 or
            ((not args.headeronce) and sys.stdout.isatty() and iteration % height == 0)):
            formatter.print_header()
            formatter.print_divider()

        last_path = []
        for d in diff:
            if args.fullname:
                name = d.name if args.exact else format_dataset(d.name, name_width)
            else:
                name, last_path = print_format_dataset(d.name, last_path, name_width, print=formatter.print)

            formatter.print_columns(name, d.reads, d.writes, d.nread, d.nwritten, d.rareq_sz, d.wareq_sz)

        if not (args.scripted or args.overwrite):
            formatter.print_divider()

        formatter.flush(lines = height if args.overwrite else None)

except KeyboardInterrupt:
    print('')
